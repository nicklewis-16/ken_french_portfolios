{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction: Fama / French Replication\n",
    "\n",
    "Each year (usually at the end of June), portfolios are published to the Fama / French data library. These portfolios consist of numerous univariate and bivariate sorts, with a wide variety of factors. Analysis is then conducted on each of these sorts using CRPS and Compustat data. The resulting tables include monthly value and equal weighted returns, daily returns, annual returns, the monthly number of firms in each portfolio, and much more. Our mission is to replicate a small subset of those portfolios, using the brief descrpitions provided on the website for how each portfolio was structured."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Pulling Data from Ken French Website using `pandas_datareader`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The specific portfolios we are attemtping to replicate are the following:\n",
    "\n",
    "* Bivariate (univariate) sorts formed on size and earnings/price, size and cashflow/price, and size and dividend yield\n",
    "* Bivariate sorts formed on operating profitability and investment\n",
    "* Each of the “5 industry portfolios” and “49 industry portfolios”\n",
    "\n",
    "To begin, we pulled the final data from online so we could reference it throughout the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_datareader.famafrench import get_available_datasets\n",
    "import pandas_datareader.data as web\n",
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "from pull_test_data import *\n",
    "import load_CRSP_Compustat\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import config\n",
    "import warnings\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import zipfile\n",
    "import csv\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_portfolio_data_to_excel(portfolio_descriptions):\n",
    "    \"\"\"\n",
    "    Fetches data for each portfolio and saves it to an Excel file, with descriptions and data in separate sheets.\n",
    "\n",
    "    Args:\n",
    "        portfolio_descriptions (dict): A dictionary containing portfolio names as keys and tuples of start and end dates as values.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    for portfolio_name, (start_date, end_date) in portfolio_descriptions.items():\n",
    "        # Fetch data for the portfolio\n",
    "        data = web.DataReader(portfolio_name, 'famafrench', start=start_date, end=end_date)\n",
    "        \n",
    "        # Define the Excel file path\n",
    "        excel_path = filedir / f\"{portfolio_name.replace('/', '_')}.xlsx\"  # Ensure the name is file-path friendly\n",
    "        with pd.ExcelWriter(excel_path, engine='xlsxwriter') as writer:\n",
    "            # Write the description to the first sheet\n",
    "            if 'DESCR' in data:\n",
    "                description_df = pd.DataFrame([data['DESCR']], columns=['Description'])\n",
    "                description_df.to_excel(writer, sheet_name='Description', index=False)\n",
    "            \n",
    "            # Write each table in the data to subsequent sheets\n",
    "            for table_key, df in data.items():\n",
    "                if table_key == 'DESCR':\n",
    "                    continue  # Skip the description since it's already handled\n",
    "                sheet_name = str(table_key)  # Naming sheets by their table_key\n",
    "                df.to_excel(writer, sheet_name=sheet_name[:31])  # Sheet name limited to 31 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_and_download(base_url, filedir, portfolios):\n",
    "    \"\"\"\n",
    "    Scrapes the webpage content from the given base URL, filters the relevant links,\n",
    "    and downloads and extracts the ZIP files for the portfolios of interest.\n",
    "\n",
    "    Args:\n",
    "        base_url (str): The base URL of the webpage to scrape.\n",
    "        filedir (str): The directory where the downloaded files will be saved.\n",
    "        portfolios (list): A list of portfolio names to filter the links.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Fetch the webpage content\n",
    "    response = requests.get(base_url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch {base_url}\")\n",
    "        return\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Filter the <a> tags to find relevant links\n",
    "    links = soup.find_all('a', href=True)\n",
    "    for link in links:\n",
    "        href = link.get('href')\n",
    "        if href and \"CSV.zip\" in href:\n",
    "            # Check if the link matches any portfolios of interest\n",
    "            portfolio_name = href.split(\"_CSV.zip\")[0]\n",
    "            if any(portfolio in portfolio_name for portfolio in portfolios):\n",
    "                full_url = urljoin(base_url, href)\n",
    "                print(f\"Found: {full_url}\")\n",
    "                download_and_extract_zip(full_url, filedir, portfolio_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     save_portfolio_data_to_excel(portfolio_descriptions)\n",
    "#     scrape_and_download(base_url, filedir, portfolios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon completing this step, various excel files appeared within our /data folder. An example of the descriptions for each sheet of data for one set of portfolios is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 Industry Portfolios\n",
      "---------------------\n",
      "\n",
      "This file was created by CMPT_IND_RETS using the 202401 CRSP database. It contains value- and equal-weighted returns for 5 industry portfolios. The portfolios are constructed at the end of June. The annual returns are from January to December. Missing data are indicated by -99.99 or -999. Copyright 2024 Kenneth R. French\n",
      "\n",
      "  0 : Average Value Weighted Returns -- Monthly (1170 rows x 5 cols)\n",
      "  1 : Average Equal Weighted Returns -- Monthly (1170 rows x 5 cols)\n",
      "  2 : Average Value Weighted Returns -- Annual (97 rows x 5 cols)\n",
      "  3 : Average Equal Weighted Returns -- Annual (97 rows x 5 cols)\n",
      "  4 : Number of Firms in Portfolios (1170 rows x 5 cols)\n",
      "  5 : Average Firm Size (1170 rows x 5 cols)\n",
      "  6 : Sum of BE / Sum of ME (98 rows x 5 cols)\n",
      "  7 : Value-Weighted Average of BE/ME (98 rows x 5 cols)\n"
     ]
    }
   ],
   "source": [
    "sheet = pd.read_excel(f'../data/famafrench/5_Industry_Portfolios.xlsx', 'Description')\n",
    "print(sheet['Description'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Pulling raw data from CRSP and compustat\n",
    "\n",
    "Once seeing what the final product should look like, we need to pull to raw data off the web to start our construction. The return data is gathered from CRSP, whereas much of the other relevant data needs to be merged from compustat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_CRSP_stock():\n",
    "    \"\"\"\n",
    "    Pulls CRSP stock data from the WRDS database.\n",
    "\n",
    "    Parameters:\n",
    "    - wrds_username (str): WRDS username (default: WRDS_USERNAME)\n",
    "\n",
    "    Returns:\n",
    "    - crsp_monthly (pd.DataFrame): CRSP stock data\n",
    "\n",
    "    \"\"\"\n",
    "    crsp_monthly_query = (\n",
    "    \"SELECT msf.permno, msf.permco, msf.date, \"\n",
    "            \"date_trunc('month', msf.date)::date as month, \"\n",
    "            \"msf.ret, msf.retx, msf.shrout, msf.altprc, \"\n",
    "            \"msenames.exchcd, msenames.siccd, \"\n",
    "            \"msedelist.dlret, msedelist.dlstcd \"\n",
    "        \"FROM crsp.msf AS msf \"\n",
    "        \"LEFT JOIN crsp.msenames as msenames \"\n",
    "        \"ON msf.permno = msenames.permno AND \"\n",
    "        \"msenames.namedt <= msf.date AND \"\n",
    "        \"msf.date <= msenames.nameendt \"\n",
    "        \"LEFT JOIN crsp.msedelist as msedelist \"\n",
    "        \"ON msf.permno = msedelist.permno AND \"\n",
    "        \"date_trunc('month', msf.date)::date = \"\n",
    "        \"date_trunc('month', msedelist.dlstdt)::date \"\n",
    "        f\"WHERE msf.date BETWEEN '{start_date}' AND '{end_date}' \"\n",
    "        \"AND msenames.shrcd IN (10, 11)\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_compustat():\n",
    "    \"\"\"\n",
    "    Pulls financial data from the Compustat database for a specified time period.\n",
    "\n",
    "    Parameters:\n",
    "    - wrds_username (str): The username for accessing the WRDS database. Defaults to WRDS_USERNAME.\n",
    "\n",
    "    Returns:\n",
    "    - compustat (DataFrame): A DataFrame containing the financial data from the Compustat database.\n",
    "\n",
    "    \"\"\"\n",
    "    compustat_query = (\n",
    "    \"SELECT gvkey, datadate, seq, ceq, at, lt, txditc, txdb, itcb,  pstkrv, \"\n",
    "            \"pstkl, pstk, capx, oancf, sale, cogs, xint, xsga, sich, ni, ebit, dp \"\n",
    "        \"FROM comp.funda \"\n",
    "        \"WHERE indfmt = 'INDL' \"\n",
    "            \"AND datafmt = 'STD' \"\n",
    "            \"AND consol = 'C' \"\n",
    "            f\"AND datadate BETWEEN '{start_date}' AND '{end_date}'\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have these 2 tables, we need an additional one to be able to link them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_CRSP_Comp_Link_Table(crsp_monthly):\n",
    "    \"\"\"\n",
    "    Pulls the CRSP Compustat Link Table from the WRDS database and merges it with the CRSP monthly data.\n",
    "\n",
    "    Parameters:\n",
    "    - wrds_username (str): The username for accessing the WRDS database.\n",
    "    - crsp_monthly (pd.DataFrame): The CRSP monthly data.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The merged data containing the CRSP Compustat Link Table.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    ccmxpf_linktable_query = (\n",
    "    \"SELECT lpermno AS permno, gvkey, linkdt, \"\n",
    "            \"COALESCE(linkenddt, CURRENT_DATE) AS linkenddt \"\n",
    "        \"FROM crsp.ccmxpf_linktable \"\n",
    "        \"WHERE linktype IN ('LU', 'LC') \"\n",
    "            \"AND linkprim IN ('P', 'C') \"\n",
    "            \"AND usedflag = 1\"\n",
    "    )\n",
    "\n",
    "    ccmxpf_linktable = pd.read_sql_query(\n",
    "    sql=ccmxpf_linktable_query,\n",
    "    con=wrds,\n",
    "    dtype={\"permno\": int, \"gvkey\": str},\n",
    "    parse_dates={\"linkdt\", \"linkenddt\"}\n",
    "    )\n",
    "    ccm_links = (crsp_monthly\n",
    "    .merge(ccmxpf_linktable, how=\"inner\", on=\"permno\")\n",
    "    .query(\"~gvkey.isnull() & (date >= linkdt) & (date <= linkenddt)\")\n",
    "    .get([\"permno\", \"gvkey\", \"date\"])\n",
    "    )\n",
    "\n",
    "    crsp_monthly = (crsp_monthly\n",
    "    .merge(ccm_links, how=\"left\", on=[\"permno\", \"date\"])\n",
    "    )\n",
    "    \n",
    "    return crsp_monthly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running these, the CRSP data should have the following variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3420181 entries, 0 to 3481102\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Dtype         \n",
      "---  ------    -----         \n",
      " 0   permno    int64         \n",
      " 1   permco    int64         \n",
      " 2   date      datetime64[ns]\n",
      " 3   month     datetime64[ns]\n",
      " 4   ret       float64       \n",
      " 5   retx      float64       \n",
      " 6   shrout    float64       \n",
      " 7   altprc    float64       \n",
      " 8   exchcd    int64         \n",
      " 9   siccd     int64         \n",
      " 10  me        float64       \n",
      " 11  me_lag    float64       \n",
      " 12  exchange  object        \n",
      " 13  ret_adj   float64       \n",
      "dtypes: datetime64[ns](2), float64(7), int64(4), object(1)\n",
      "memory usage: 391.4+ MB\n"
     ]
    }
   ],
   "source": [
    "crsp_monthly = pd.read_parquet('../data/pulled/CRSP_stock.parquet')\n",
    "crsp_monthly.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "permno and permco are unique indentifies for each company on the exchange. Date and month are straighforward. Further, ret is the monthly return of the equity, while retx is the return without dividends. shrout represents the number of outstading shares, while altprc gives the share price. exchcd takes an integer value that stands for the main exchange listed on (NASDAQ, NYSE, AMEX, or Other). Finally, siccd are SIC codes that also serve as identifiers.\n",
    "\n",
    "The code for the other variables can be found below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mktcp\n",
    "Calculating the monthly market equity for each firm using shares outstanding and share price. In addition, we also have a lagged market cap as some of the later calculations involve looking at the market equity of previous periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "mktcap_lag = (crsp_monthly\n",
    "    .assign(\n",
    "        month=lambda x: x[\"month\"]+pd.DateOffset(months=1),\n",
    "        mktcap_lag=lambda x: x[\"me\"]\n",
    "    )\n",
    "    .get([\"permno\", \"month\", \"me_lag\"])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## exchange\n",
    "This is simply hardcoding the exchange from the exchcd variable.\n",
    "- NYSE had code 1 or 31\n",
    "- AMEX has code 2 or 32\n",
    "- NASDAQ has code 3 or 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_exchange(exchcd):\n",
    "        \n",
    "        # FILL IN THE CODE HERE\n",
    "\n",
    "    crsp_monthly[\"exchange\"] = (crsp_monthly[\"exchcd\"]\n",
    "        .apply(assign_exchange)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the cleaning has been done to the CRSP data, the summary statistics should match the table below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permno</th>\n",
       "      <th>permco</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>ret</th>\n",
       "      <th>retx</th>\n",
       "      <th>shrout</th>\n",
       "      <th>altprc</th>\n",
       "      <th>exchcd</th>\n",
       "      <th>siccd</th>\n",
       "      <th>me</th>\n",
       "      <th>me_lag</th>\n",
       "      <th>ret_adj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.420181e+06</td>\n",
       "      <td>3.420181e+06</td>\n",
       "      <td>3420181</td>\n",
       "      <td>3420181</td>\n",
       "      <td>3.377429e+06</td>\n",
       "      <td>3.377429e+06</td>\n",
       "      <td>3.420179e+06</td>\n",
       "      <td>3.406788e+06</td>\n",
       "      <td>3.420181e+06</td>\n",
       "      <td>3.420181e+06</td>\n",
       "      <td>3.406667e+06</td>\n",
       "      <td>3.379253e+06</td>\n",
       "      <td>3.377434e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.297648e+04</td>\n",
       "      <td>1.796992e+04</td>\n",
       "      <td>1994-05-03 03:45:15.023678592</td>\n",
       "      <td>1994-04-04 04:37:35.598519168</td>\n",
       "      <td>1.127520e-02</td>\n",
       "      <td>1.001186e-02</td>\n",
       "      <td>5.042633e+07</td>\n",
       "      <td>3.494201e+01</td>\n",
       "      <td>2.249042e+00</td>\n",
       "      <td>4.728491e+03</td>\n",
       "      <td>2.115456e+03</td>\n",
       "      <td>2.114359e+03</td>\n",
       "      <td>1.124619e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1960-01-29 00:00:00</td>\n",
       "      <td>1960-01-01 00:00:00</td>\n",
       "      <td>-9.956900e-01</td>\n",
       "      <td>-9.956900e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.832500e+03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.056250e-02</td>\n",
       "      <td>1.718750e-02</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.564600e+04</td>\n",
       "      <td>6.300000e+03</td>\n",
       "      <td>1982-05-28 00:00:00</td>\n",
       "      <td>1982-05-01 00:00:00</td>\n",
       "      <td>-6.730800e-02</td>\n",
       "      <td>-6.878800e-02</td>\n",
       "      <td>3.028000e+06</td>\n",
       "      <td>1.810000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.311000e+03</td>\n",
       "      <td>1.998862e+01</td>\n",
       "      <td>2.014950e+01</td>\n",
       "      <td>-6.730800e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.427900e+04</td>\n",
       "      <td>1.482000e+04</td>\n",
       "      <td>1994-07-29 00:00:00</td>\n",
       "      <td>1994-07-01 00:00:00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.153000e+06</td>\n",
       "      <td>1.041000e+01</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>4.469000e+03</td>\n",
       "      <td>8.820000e+01</td>\n",
       "      <td>8.859967e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.973800e+04</td>\n",
       "      <td>2.312700e+04</td>\n",
       "      <td>2006-01-31 00:00:00</td>\n",
       "      <td>2006-01-01 00:00:00</td>\n",
       "      <td>7.142900e-02</td>\n",
       "      <td>7.002800e-02</td>\n",
       "      <td>3.007200e+07</td>\n",
       "      <td>2.487500e+01</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>6.311000e+03</td>\n",
       "      <td>4.930639e+02</td>\n",
       "      <td>4.946360e+02</td>\n",
       "      <td>7.142900e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.343600e+04</td>\n",
       "      <td>5.975000e+04</td>\n",
       "      <td>2023-12-29 00:00:00</td>\n",
       "      <td>2023-12-01 00:00:00</td>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>2.920640e+10</td>\n",
       "      <td>5.467250e+05</td>\n",
       "      <td>3.300000e+01</td>\n",
       "      <td>9.999000e+03</td>\n",
       "      <td>3.071345e+06</td>\n",
       "      <td>3.071345e+06</td>\n",
       "      <td>2.400000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.768620e+04</td>\n",
       "      <td>1.488959e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.839305e-01</td>\n",
       "      <td>1.839464e-01</td>\n",
       "      <td>2.689379e+08</td>\n",
       "      <td>2.138450e+03</td>\n",
       "      <td>9.155700e-01</td>\n",
       "      <td>2.228234e+03</td>\n",
       "      <td>1.957998e+04</td>\n",
       "      <td>1.944427e+04</td>\n",
       "      <td>1.839675e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             permno        permco                           date  \\\n",
       "count  3.420181e+06  3.420181e+06                        3420181   \n",
       "mean   5.297648e+04  1.796992e+04  1994-05-03 03:45:15.023678592   \n",
       "min    1.000000e+04  3.000000e+00            1960-01-29 00:00:00   \n",
       "25%    2.564600e+04  6.300000e+03            1982-05-28 00:00:00   \n",
       "50%    5.427900e+04  1.482000e+04            1994-07-29 00:00:00   \n",
       "75%    7.973800e+04  2.312700e+04            2006-01-31 00:00:00   \n",
       "max    9.343600e+04  5.975000e+04            2023-12-29 00:00:00   \n",
       "std    2.768620e+04  1.488959e+04                            NaN   \n",
       "\n",
       "                               month           ret          retx  \\\n",
       "count                        3420181  3.377429e+06  3.377429e+06   \n",
       "mean   1994-04-04 04:37:35.598519168  1.127520e-02  1.001186e-02   \n",
       "min              1960-01-01 00:00:00 -9.956900e-01 -9.956900e-01   \n",
       "25%              1982-05-01 00:00:00 -6.730800e-02 -6.878800e-02   \n",
       "50%              1994-07-01 00:00:00  0.000000e+00  0.000000e+00   \n",
       "75%              2006-01-01 00:00:00  7.142900e-02  7.002800e-02   \n",
       "max              2023-12-01 00:00:00  2.400000e+01  2.400000e+01   \n",
       "std                              NaN  1.839305e-01  1.839464e-01   \n",
       "\n",
       "             shrout        altprc        exchcd         siccd            me  \\\n",
       "count  3.420179e+06  3.406788e+06  3.420181e+06  3.420181e+06  3.406667e+06   \n",
       "mean   5.042633e+07  3.494201e+01  2.249042e+00  4.728491e+03  2.115456e+03   \n",
       "min    0.000000e+00 -1.832500e+03  1.000000e+00  0.000000e+00  1.056250e-02   \n",
       "25%    3.028000e+06  1.810000e+00  1.000000e+00  3.311000e+03  1.998862e+01   \n",
       "50%    9.153000e+06  1.041000e+01  3.000000e+00  4.469000e+03  8.820000e+01   \n",
       "75%    3.007200e+07  2.487500e+01  3.000000e+00  6.311000e+03  4.930639e+02   \n",
       "max    2.920640e+10  5.467250e+05  3.300000e+01  9.999000e+03  3.071345e+06   \n",
       "std    2.689379e+08  2.138450e+03  9.155700e-01  2.228234e+03  1.957998e+04   \n",
       "\n",
       "             me_lag       ret_adj  \n",
       "count  3.379253e+06  3.377434e+06  \n",
       "mean   2.114359e+03  1.124619e-02  \n",
       "min    1.718750e-02 -1.000000e+00  \n",
       "25%    2.014950e+01 -6.730800e-02  \n",
       "50%    8.859967e+01  0.000000e+00  \n",
       "75%    4.946360e+02  7.142900e-02  \n",
       "max    3.071345e+06  2.400000e+01  \n",
       "std    1.944427e+04  1.839675e-01  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crsp_monthly.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Merging and Portfolio Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have all the data pulled down, we need to merge the CRSP and compustat data and begin calculating the appropriate metrics to assign the data to portfolios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Industry portfolios\n",
    "\n",
    "Matching on SIC codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_industry5(sic_code):\n",
    "    \"\"\"\n",
    "    Assigns an industry category based on the given SIC code.\n",
    "\n",
    "    Parameters:\n",
    "    sic_code (int): The SIC code to be categorized.\n",
    "\n",
    "    Returns:\n",
    "    str: The industry category assigned based on the SIC code range.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        sic_code = int(sic_code)  # Ensure SIC code is an integer\n",
    "    except ValueError:\n",
    "        return 'Other'  # Return 'Other' if SIC code cannot be converted to integer\n",
    "\n",
    "    # Define SIC code ranges for each industry\n",
    "    cnsmr_ranges = [(100, 999), (2000, 2399), (2700, 2749), (2770, 2799), (3100, 3199),\n",
    "                    (3940, 3989), (2500, 2519), (2590, 2599), (3630, 3659), (3710, 3711),\n",
    "                    (3714, 3714), (3716, 3716), (3750, 3751), (3792, 3792), (3900, 3939),\n",
    "                    (3990, 3999), (5000, 5999), (7200, 7299), (7600, 7699)]\n",
    "    manuf_ranges = []\n",
    "    hitec_ranges = []\n",
    "    hlth_ranges = [] ## FILL IN MISSING CODE\n",
    "\n",
    "    # Assign industry based on SIC code range\n",
    "    for start, end in cnsmr_ranges:\n",
    "        if start <= sic_code <= end:\n",
    "            return 'Cnsmr'\n",
    "            \n",
    "            # Finish Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Univariate sorts on E/P and C/P ratios\n",
    "\n",
    "Need to calculate the breakpoints for each metric and then apply the appropriate grouping to each row. An example of both steps is found below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_stocks_by_metric(dataframe, metric, category_name):\n",
    "    \"\"\"\n",
    "    Categorize stocks by a specified metric and directly append the categories to the dataframe.\n",
    "    \"\"\"\n",
    "    # Calculate breakpoints for the NYSE stocks each year to define categories\n",
    "    for year, group in dataframe.groupby('year'):\n",
    "        non_negative = group[group[metric] >= 0]\n",
    "        negative = group[group[metric] < 0]\n",
    "\n",
    "        sorted_values = non_negative[metric].sort_values()\n",
    "\n",
    "        bottom_30_bp = sorted_values.quantile(q=0.3)\n",
    "\n",
    "        # Finish quintiles and deciles\n",
    "\n",
    "        dataframe.loc[non_negative.index, category_name] = non_negative.apply(\n",
    "            lambda row: categorize_metric_exclusive(row, metric, bottom_30_bp, top_30_bp, quintiles_bp.values, deciles_bp.values), axis=1)\n",
    "        dataframe.loc[negative.index, category_name] = [['Negative Values']] * len(negative)\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_metric_exclusive(row, metric, bottom_30_bp, top_30_bp, quintiles_bp, deciles_bp):\n",
    "    \"\"\"\n",
    "    Determine categories for a given metric value within a row.\n",
    "    This is a placeholder function. Replace its internals based on actual categorization logic.\n",
    "    \"\"\"\n",
    "    value = row[metric]\n",
    "    categories = []\n",
    "\n",
    "    if value < 0:\n",
    "        categories.append('<=0')\n",
    "    \n",
    "    # COMPLETE\n",
    "\n",
    "    quintiles = np.searchsorted(quintiles_bp, value, side='right')\n",
    "    categories.append(f'Qnt {quintiles+1}')\n",
    "\n",
    "    deciles = np.searchsorted(deciles_bp, value, side='right')\n",
    "    categories.append(f'Dec {deciles+1}')\n",
    "\n",
    "    return categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Bivariate sorts on Operating Profitability and Investment\n",
    "\n",
    "These metrics are already calculated within compustat, so the only goal here is to assign each observation to the appropriate quintile for each metric. The below assignment function can come in handy here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_portfolio(data, sorting_variable, n_portfolios):\n",
    "    \"\"\"Assign portfolio for a given sorting variable.\"\"\"\n",
    "    \n",
    "    breakpoints = (data\n",
    "      .get(sorting_variable)\n",
    "      .quantile(np.linspace(0, 1, num=n_portfolios+1), \n",
    "                interpolation=\"linear\")\n",
    "      .drop_duplicates()\n",
    "    )\n",
    "    breakpoints.iloc[0] = -np.Inf\n",
    "    breakpoints.iloc[breakpoints.size-1] = np.Inf\n",
    "    \n",
    "    assigned_portfolios = pd.cut(\n",
    "      data[sorting_variable],\n",
    "      bins=breakpoints,\n",
    "      labels=range(1, breakpoints.size),\n",
    "      include_lowest=True,\n",
    "      right=False\n",
    "    )\n",
    "    \n",
    "    return assigned_portfolios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, tables can be formed by grouping on the portfolio type(s) and calculating returns based on desired weightings (mainly value and equal weight)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ccm4['weight'] = ccm4['me'] / ccm4.groupby(['date', 'opport', 'invport'])['me'].transform('sum')\n",
    "ccm4['weighted_ret'] = ccm4['retx'] * ccm4['weight']\n",
    "vwret_m = ccm4.groupby(['date', 'opport', 'invport'])['weighted_ret'].sum().reset_index(name='value_weighted_ret')\n",
    "\n",
    "ccm4['equal_weight'] = 1 / ccm4.groupby(['date', 'opport', 'invport'])['permno'].transform('count')\n",
    "ccm4['equal_weighted_ret'] = ccm4['retx'] * ccm4['equal_weight']\n",
    "ewret_m = ccm4.groupby(['date', 'opport', 'invport'])['equal_weighted_ret'].sum().reset_index(name='equal_weighted_ret') -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GOOD LUCK!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
